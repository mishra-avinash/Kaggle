{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function, Variable\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.U_Net import UNet\n",
    "from src.generator import train_generator, test_generator\n",
    "\n",
    "from src.utils import run_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./data/\"\n",
    "train_img_dir = \"./data/train/\"\n",
    "test_img_dir = \"./data/test/\"\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "category_num = 46 + 1\n",
    "\n",
    "ratio = 8\n",
    "\n",
    "epoch_num = 1\n",
    "batch_size = 4\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(os.listdir(\"./data/train/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>6068157 7 6073371 20 6078584 34 6083797 48 608...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>6323163 11 6328356 32 6333549 53 6338742 75 63...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>8521389 10 8526585 30 8531789 42 8537002 46 85...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>12903854 2 12909064 7 12914275 10 12919485 15 ...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n",
       "      <td>10837337 5 10842542 14 10847746 24 10852951 33...</td>\n",
       "      <td>5214</td>\n",
       "      <td>3676</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ImageId  \\\n",
       "0  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "1  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "2  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "3  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "4  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   \n",
       "\n",
       "                                       EncodedPixels  Height  Width ClassId  \n",
       "0  6068157 7 6073371 20 6078584 34 6083797 48 608...    5214   3676       6  \n",
       "1  6323163 11 6328356 32 6333549 53 6338742 75 63...    5214   3676       0  \n",
       "2  8521389 10 8526585 30 8531789 42 8537002 46 85...    5214   3676      28  \n",
       "3  12903854 2 12909064 7 12914275 10 12919485 15 ...    5214   3676      31  \n",
       "4  10837337 5 10842542 14 10847746 24 10852951 33...    5214   3676      32  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(input_dir + \"train.csv\")\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(n_channels=3, n_classes=category_num).to(device)\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b111be99fba4929b00db281d7598361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 01epoch  /    0iter:    3.841593  \n",
      "train loss in 01epoch  /  100iter:    1.3038623 \n",
      "train loss in 01epoch  /  200iter:    1.1614525 \n",
      "train loss in 01epoch  /  300iter:    1.128743  \n",
      "train loss in 01epoch  /  400iter:    1.1072618 \n",
      "train loss in 01epoch  /  500iter:    1.0880041 \n",
      "train loss in 01epoch  /  600iter:    1.082367  \n",
      "train loss in 01epoch  /  700iter:    1.0788356 \n",
      "train loss in 01epoch  /  800iter:    1.0730438 \n",
      "train loss in 01epoch  /  900iter:    1.0719689 \n",
      "train loss in 01epoch  / 1000iter:    1.0646555 \n",
      "train loss in 01epoch  / 1100iter:    1.0606396 \n",
      "train loss in 01epoch  / 1200iter:    1.0542481 \n",
      "train loss in 01epoch  / 1300iter:    1.0500518 \n",
      "train loss in 01epoch  / 1400iter:    1.0455208 \n",
      "train loss in 01epoch  / 1500iter:    1.0376431 \n",
      "train loss in 01epoch  / 1600iter:    1.0302224 \n",
      "train loss in 01epoch  / 1700iter:    1.0247685 \n",
      "train loss in 01epoch  / 1800iter:    1.016327  \n",
      "train loss in 01epoch  / 1900iter:    1.0127292 \n",
      "train loss in 01epoch  / 2000iter:    1.0090562 \n",
      "train loss in 01epoch  / 2100iter:    1.0028308 \n",
      "train loss in 01epoch  / 2200iter:    0.99810211\n",
      "train loss in 01epoch  / 2300iter:    0.99364047\n",
      "train loss in 01epoch  / 2400iter:    0.98884647\n",
      "train loss in 01epoch  / 2500iter:    0.9838231 \n",
      "\n",
      "train 1epoch loss(2511iteration):    0.98297116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a987fea47e14235ac79e59e210b0483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss in 01epoch  /    0iter:    0.43228686\n",
      "valid loss in 01epoch  /  100iter:    0.85554443\n",
      "valid loss in 01epoch  /  200iter:    0.87114752\n",
      "valid loss in 01epoch  /  300iter:    0.85979364\n",
      "\n",
      "valid 1epoch loss(349iteration):    0.85964255\n"
     ]
    }
   ],
   "source": [
    "val_sta = 73352\n",
    "val_end = 83351\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "for epoch in range(epoch_num):\n",
    "    epoch_trn_loss = 0\n",
    "    train_len = 0\n",
    "    net.train()\n",
    "    for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size,category_num,\n",
    "                                                                    WIDTH,HEIGHT))):\n",
    "        X = torch.tensor(X_trn, dtype=torch.float32).to(device)\n",
    "        Y = torch.tensor(Y_trn, dtype=torch.long).to(device)\n",
    "        train_len += len(X)\n",
    "        \n",
    "        #Y_flat = Y.view(-1)\n",
    "        mask_pred = net(X)\n",
    "        #mask_prob = torch.softmax(mask_pred, dim=1)\n",
    "        #mask_prob_flat = mask_prob.view(-1)\n",
    "        loss = criterion(mask_pred, Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_trn_loss += loss.item()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(\"train loss in {:0>2}epoch  /{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_trn_loss/(iteration+1)))\n",
    "        \n",
    "    train_loss.append(epoch_trn_loss/(iteration+1))\n",
    "    print(\"train {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, train_loss[-1]))\n",
    "    \n",
    "    epoch_val_loss = 0\n",
    "    val_len = 0\n",
    "    net.eval()\n",
    "    for iteration, (X_val, Y_val) in enumerate(tqdm(train_generator(train_df.iloc[val_sta:val_end, :], batch_size,category_num,\n",
    "                                                                    WIDTH,HEIGHT))):\n",
    "        X = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "        Y = torch.tensor(Y_val, dtype=torch.long).to(device)\n",
    "        val_len += len(X)\n",
    "        \n",
    "        #Y_flat = Y.view(-1)\n",
    "        \n",
    "        mask_pred = net(X)\n",
    "        #mask_prob = torch.softmax(mask_pred, dim=1)\n",
    "        #mask_prob_flat = mask_prob.view(-1)\n",
    "        loss = criterion(mask_pred, Y)\n",
    "        epoch_val_loss += loss.item()\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(\"valid loss in {:0>2}epoch  /{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_val_loss/(iteration+1)))\n",
    "        \n",
    "    valid_loss.append(epoch_val_loss/(iteration+1))\n",
    "    print(\"valid {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, valid_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(input_dir + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "sub_list = []\n",
    "net.eval()\n",
    "for img_name, img in test_generator(sample_df,WIDTH,HEIGHT):\n",
    "    X = torch.tensor(img, dtype=torch.float32).to(device)\n",
    "    mask_pred = net(X)\n",
    "    mask_pred = mask_pred.cpu().detach().numpy()\n",
    "    mask_prob = np.argmax(mask_pred, axis=1)\n",
    "    mask_prob = mask_prob.ravel(order='F')\n",
    "    class_dict = run_length(mask_prob,category_num)\n",
    "    if len(class_dict) == 0:\n",
    "        sub_list.append([img_name, \"1 1\", 1])\n",
    "    else:\n",
    "        for key, val in class_dict.items():\n",
    "            sub_list.append([img_name, \" \".join(map(str, val)), key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(sub_list, columns=sample_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
